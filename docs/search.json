[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Mathematical Ecology",
    "section": "",
    "text": "Introduction to Mathematical Ecology\nThese pages contain lecture notes, lab worksheets, and exercises for Mathematical Ecology.",
    "crumbs": [
      "Introduction to Mathematical Ecology"
    ]
  },
  {
    "objectID": "lec01-BirthProcess.html",
    "href": "lec01-BirthProcess.html",
    "title": "1  The Simple Death Process",
    "section": "",
    "text": "1.1 A single individual\nLet \\(X(t)\\) be a random variable denoting the state of a given organism at time \\(t\\), with one indicating alive and zero dead.\nThe main assumptions of the simple death process are as follows:\nWe express these assumptions precisely with statements about conditional probabilities. For every interval \\([t,t+\\tau]\\), with \\(t\\) and \\(\\tau\\) nonnegative, we assume that \\[\\text{Pr}\\left(\\  X(t+\\tau)=0  \\ \\mid\\  X(t)=1 \\ \\right) = \\mu\\tau + o(\\tau). \\tag{1.1}\\]\nLittle-o, \\(o(\\tau)\\), is a mathematical shorthand for negligible. Technically, we say a function, \\(f(\\tau)\\) is \\(o(\\tau^k)\\) if \\(\\displaystyle\\lim_{t\\to0} \\dfrac{f(\\tau)}{\\tau^k} = 0\\). That is, \\(f\\) goes to zero faster than \\(\\tau^k\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Simple Death Process</span>"
    ]
  },
  {
    "objectID": "lec01-BirthProcess.html#a-single-individual",
    "href": "lec01-BirthProcess.html#a-single-individual",
    "title": "1  The Simple Death Process",
    "section": "",
    "text": "at any time, the individual is in one of two possible states, alive (1) or dead (0);\nif an individual is alive at time \\(t\\), the probability of that individual dying before time \\(t+\\tau\\) is proportional to the waiting time \\(\\tau\\) and independent of \\(t\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Simple Death Process</span>"
    ]
  },
  {
    "objectID": "lec01-BirthProcess.html#event-times",
    "href": "lec01-BirthProcess.html#event-times",
    "title": "1  The Simple Death Process",
    "section": "1.2 Event times",
    "text": "1.2 Event times\nConsider again a single individual alive at time zero, and let \\(T\\) be the random variable denoting the time the individual dies. From Equation 1.1, we know that the probability the organism dies between times \\(t\\) and \\(t+\\tau\\) must be \\[\\text{Pr}\\left(\\  T\\in (t,t+\\tau]  \\ \\mid\\  T&gt;t \\ \\right) = \\mu\\tau + o(\\tau).\\] From the definition of conditional probability and the fact that \\(\\text{Pr}\\left(\\ T&gt;t \\right)\\) is a nonincreasing function of \\(t\\), we know that \\[\\text{Pr}\\left(\\  T\\in (t,t+\\tau]  \\ \\mid\\  T&gt;t \\ \\right) = \\frac{\\text{Pr}\\left(\\ T&gt;t \\right) - \\text{Pr}\\left(\\ T&gt;t+\\tau \\right)}{\\text{Pr}\\left(\\ T&gt;t \\right)}.\\] Equating the two expressions leads to \\[\\begin{align*}\n  \\frac{\\text{Pr}\\left(\\ T&gt;t \\right) - \\text{Pr}\\left(\\ T&gt;t+\\tau \\right)}{\\text{Pr}\\left(\\ T&gt;t \\right)} &= \\mu\\tau + o(\\tau) \\\\\n  \\frac{\\text{Pr}\\left(\\ T&gt;t \\right) - \\text{Pr}\\left(\\ T&gt;t+\\tau \\right)}{\\tau} &= \\mu \\text{Pr}\\left(\\ T&gt;t \\right) + \\frac{o(\\tau)}{\\tau}\n\\end{align*}\\] Finally, taking a limit as \\(\\tau\\to0\\) leads us to a differential equation for \\(\\text{Pr}\\left(\\ T&gt;t \\right)\\). \\[\\frac{d}{dt}\\text{Pr}\\left(\\ T&gt;t \\right) = - \\lim_{\\tau\\to0}\\frac{\\text{Pr}\\left(\\ T&gt;t \\right) - \\text{Pr}\\left(\\ T&gt;t+\\tau \\right)}{\\tau} = - \\mu \\text{Pr}\\left(\\ T&gt;t \\right)\\] Solving this equation with the initial condition \\(\\text{Pr}\\left(\\ T&gt;0 \\right)=1\\), we find that \\[\\text{Pr}\\left(\\ T&gt;t \\right) = \\exp\\left(-\\displaystyle\\int_0^t \\mu(s)\\, ds\\right).\\] If the switching rate is constant, then \\(\\text{Pr}\\left(\\ T&gt;t \\right) = e^{-\\mu t}\\). That is, \\(T\\) has an exponential distribution with rate \\(\\mu\\).\nThis exponential distribution of event times, sometimes called sojourn times, persists across many compartmental models. The assumption that the mortality rate, \\(\\mu\\), is constant and does not depend on time or any aspects of the individual, such as age, implies an exponential distribution of event times with its skew towards short times.\n\nExercise 1.1 Show that the mean of the exponential distribution with rate \\(\\mu\\) is \\(\\frac{1}{\\mu}\\) and hence \\(\\mu\\) is the reciprocal of the life expectancy.\n\n\nExercise 1.2 Compute the 10th and 90th percentiles of an exponential distribution with rate \\(\\mu\\). That is, find the times \\(q\\) for which \\(\\text{Pr}\\left(\\ T&lt;q \\right) \\in \\{0.1,0.9\\}\\)\n\n\n\\[\\text{Pr}\\left(\\ T&lt;q \\right) = 1 - \\text{Pr}\\left(\\ T&gt;q \\right) = 1 - e^{-\\mu q}\\] Setting this to \\(p\\) and solving for \\(q\\) in terms of \\(p\\) leads to \\[q = -\\frac{1}{\\mu}\\log p\\] For \\(p= 0.1\\), we find \\(q\\approx\\frac{2.3}{\\mu}\\), and for \\(p=0.9\\), we find \\(q\\approx\\frac{0.1}{\\mu}\\). In other words, 10% of individuals survive at least twice as long as the mean, and 10% die before reaching one tenth the mean age.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Simple Death Process</span>"
    ]
  },
  {
    "objectID": "lec01-BirthProcess.html#a-single-individual-1",
    "href": "lec01-BirthProcess.html#a-single-individual-1",
    "title": "1  The Simple Death Process",
    "section": "2.1 A single individual",
    "text": "2.1 A single individual\nThus, in a population of a single individual, \\[\\begin{align*}\n    \\text{Pr}\\left(\\ \\text{exactly 1 birth in $[t,t+\\tau]$} \\right) &= b\\tau + o(\\tau), \\\\\n    \\text{Pr}\\left(\\ \\text{more than 1 birth in $[t,t+\\tau]$} \\right) &= o(\\tau), \\\\\n    \\text{Pr}\\left(\\ \\text{no births in $[t,t+\\tau]$} \\right) &= 1 - b\\tau + o(\\tau), \\\\\n\\end{align*}\\]\nLet \\(p_n(t)\\) be the probability the individual has \\(n\\) offspring in the interval \\((0,t)\\). From the transition probabilities specified above, \\[\\begin{align*}\n  p_{n}(t+\\tau) &= \\left(1 - b\\tau + o(\\tau)\\right)p_{n}(t) + \\left(b\\tau + o(\\tau)\\right)p_{n-1}(t), \\quad n\\in{1,2,\\dots} \\\\\n  p_0(t+\\tau)   &= \\left(1 - b\\tau + o(\\tau)\\right)p_{n}(t), \\quad n = 0.\n\\end{align*}\\]\nRearranging the terms and taking a limit as \\(\\tau\\to0\\) leads to the following system of differential equations: \\[\\begin{align*}\n  \\frac{d}{dt}p_n(t) &= -b p_{n}(t) + b p_{n-1}(t), \\quad n&gt;0, \\\\\n  \\frac{d}{dt}p_0(t) &= -b p_{0}(t). \\\\\n\\end{align*}\\]\n\nExercise 2.1 Show that the solution to the above system of differential equations with \\(p_0(0)=1\\) and \\(p_n(0) = 0\\), \\(n\\in\\{1,2,3,\\dots\\}\\) is \\[p_n(t) = \\frac{(b t)^ne^{-b t}}{n!}.\\]\n\nBy the above exercise, the assumption that the probability of a birth in a short interval of time is proportional to the length of the interval leads to the births having a Poisson distribution with rate \\(bt\\).\nNow let \\(T(t)\\) be the probability that the next birth event happens within a time \\(t\\). That is, \\(T\\) is the c.d.f. for the inter-event times. This is simply the probability there is at least one birth in the interval \\((0,t)\\), thus, \\(T(t) = 1-p_0(t) = 1-e^{bt}\\). This connection between the exponential and Poisson distributions will turn out to be useful in modelling and simulation.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Simple Death Process</span>"
    ]
  },
  {
    "objectID": "lec01-BirthProcess.html#many-individuals",
    "href": "lec01-BirthProcess.html#many-individuals",
    "title": "1  The Simple Death Process",
    "section": "2.2 Many individuals",
    "text": "2.2 Many individuals\nIn a population of a \\(n\\) individuals, \\[\\begin{align*}\n  \\hbox{Pr}\\{\\hbox{1 birth in $[t,t+\\tau]$}\\} &= nb\\tau(1-b\\tau)^{n-1} = nb\\tau + o(\\tau), \\\\\n  \\hbox{Pr}\\{\\hbox{more than 1 birth in $[t,t+\\tau]$}\\} &= \\begin{pmatrix} n\\\\m \\end{pmatrix}(b\\tau)^m(1-b\\tau)^{n-m} = o(\\tau), \\\\\n  \\hbox{Pr}\\{\\hbox{no births in $[t,t+\\tau]$}\\} &= 1 - nb\\tau + o(\\tau),\n\\end{align*}\\]\n\n2.2.1 The ODE for the mean\nThe master equation for the process relates the probabilities at each time step. \\[\\begin{align*}\n  p_n(t+\\tau) &= p_{n-1}(t)\\cdot\\hbox{Pr}\\{\\hbox{1 birth in $[t,t+\\tau]$}\\}+p_n(t)\\cdot\\hbox{Pr}\\{\\hbox{no births in $[t,t+\\tau]$}\\} \\\\\n              &= p_{n-1}(t)(n-1)b\\tau + p_n(t)(1-bn\\tau)+o(\\tau)\n\\end{align*}\\] Rearranging the master equation yields \\[\\begin{equation*}\n  \\frac{1}{\\tau}\\left(p_n(t+\\tau)-p_n(t)\\right) = b\\left((n-1)p_{n-1}(t)-np_n(t) \\right)\n\\end{equation*}\\]\nTaking a limit leads to a sequence of ODEs, \\[\\begin{equation*}\n  \\frac{d}{dt}p_n(t) = b\\left((n-1)p_{n-1}(t)-np_n(t) \\right), \\quad n\\in\\{n_0,n_0+1,\\dots, \\quad P_{n_0-1}=0\\},\n\\end{equation*}\\] with initial conditions \\[p_n(0) = \\begin{cases} 1 & \\text{if $n=n_0$,} \\\\ 0 & \\text{otherwise.} \\end{cases}\\]\nA differential equation for the mean and variance of the process can be derived from the above system.\n\\[\\begin{align*}\n  \\frac{dM_1}{dt} = \\sum_{n=1}^\\infty n\\dot{p}_n &= \\sum_{n=1}^\\infty bn\\left ( n-1)p_{n-1} - np_n\\right) \\\\\n         &= b\\sum_{n=0}^\\infty \\left( (n+1)np_n - n^2p_n \\right) \\\\\n         &= b\\sum_{n=1}^\\infty np_n  \\\\\n     &= bM_1\n\\end{align*}\\] with the initial condition \\(M_1(0) = n_0\\).\nThis equation has the solution \\[M_1(t) = n_0e^{bt}\\]\n\\[\\begin{align*}\n  \\frac{d\\sigma^2}{dt} = \\dfrac{d}{dt}\\left(M_2-M_1^2\\right) &= \\sum_{n=1}^\\infty n^2\\dot{p}_n - 2M_1\\frac{dM_1}{dt} \\\\\n      &= \\sum_{n=1}^\\infty bn^2\\left((n-1)p_{n-1}(t) - np_n(t)\\right) - 2bM_1^2 \\\\\n      &= \\sum_{n=1}^\\infty b\\left((n+1)^2np_{n}(t) - n^3p_n(t)\\right) - 2bM_1^2 \\\\\n      &= \\sum_{n=1}^\\infty b\\left((2n^2+n)p_{n}(t) \\right) - 2bM_1^2 \\\\\n      &= b\\left(2M_2+M_1  - 2M_1^2\\right) \\\\\n      &= 2b\\sigma^2+bM_1\n\\end{align*}\\] The initial conditions are \\(\\sigma^2(0)=0\\) and \\(M_1(0)=0\\), which leads to the solution \\[\\sigma^2(t) = n_0e^{bt}(e^{bt}-1)\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Simple Death Process</span>"
    ]
  },
  {
    "objectID": "00-lab-R-intro.html",
    "href": "00-lab-R-intro.html",
    "title": "2  Introduction to R",
    "section": "",
    "text": "2.1 obtaining and installing R",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "00-lab-R-intro.html#obtaining-and-installing-r",
    "href": "00-lab-R-intro.html#obtaining-and-installing-r",
    "title": "2  Introduction to R",
    "section": "",
    "text": "Follow instructions on the r-project website\nAlternately, download and set up R studio",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "00-lab-R-intro.html#getting-help",
    "href": "00-lab-R-intro.html#getting-help",
    "title": "2  Introduction to R",
    "section": "2.2 Getting help",
    "text": "2.2 Getting help\n\nfor help for on any command type ?command at the prompt. For example ?rbinom will give you a summary of the command for generating a string of random numbers from a binomial distribution. (See https://www.r-project.org/help.html for more details.)\nIf you have a graphical interface, there is probably also a HELP button.\nand of course you will want to keep the r manuals https://cran.r-project.org/manuals.html close at hand",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "00-lab-R-intro.html#simulating-a-simple-stochastic-process",
    "href": "00-lab-R-intro.html#simulating-a-simple-stochastic-process",
    "title": "2  Introduction to R",
    "section": "2.3 Simulating a simple stochastic process",
    "text": "2.3 Simulating a simple stochastic process\nTo start, we will use R to generate some sample paths from a simple stochastic process. Let \\(N(t)\\) be the number of individuals in the population at time \\(t\\), \\(t\\in\\{0,1,\\dots\\}\\), and suppose in any given time step, any given individual will give birth with probability \\(b\\). We will need a vector to store our resulting populations, and we should specify the length of this vector in advance. We also need some initial population, say \\(N(0) = N_0\\). First, set up a vector to hold the results.\n\n\nShow the code\nT = 10\nNo = 20\nN = rep(0,length=T)\n\n\nrep stands for replicate. The result is a vector of zeros of length \\(T\\).\nNext, initialize the first entry of \\(N\\) with initial value for the simulation.\n\n\nShow the code\nN[1] = No\n\n\nWe next want to generate some births. Since we’ve assumed all individuals are reproducing independently, we model the number of births in the first time interval by a binomial distribution with parameters \\(N\\) and \\(b\\). We assign a value to \\(b\\) and then use R’s rbinom command.\n\n\nShow the code\nb = .2\nbirths = rbinom(1,N[1],b)\n\n\nTo repeat this for the rest of the times, we set up a loop.\n\n\nShow the code\nfor (t in 1:(T-1)) {\n  N[t+1] = N[t] + rbinom(1,N[t],b)\n}\n\n\nR is built to work with vectors. It is just as easy, and surprisingly, almost as quick to generate many many sample paths as it is to generate one. To store the results, we set up a matrix with \\(S\\) columns, where \\(S\\) is the number of sample paths. The resulting code is as follows.\n\n\nShow the code\n T = 10\n S = 5\n N = matrix(0,nrow = T, ncol = S)\n N[1,] = 20\n b = .2\n for (t in 1:(T-1)) {\n     N[t+1,] = N[t,] + rbinom(S,N[t,],b)\n   }\n\n\nThe third line sets up a matrix with T rows, and S columns and fills it with zeros.\nThe fourth line initializes the first row of the matrix with initial values for the simulations. Note the slight difference from matlab’s notation.\nNotice the first argument to rbinom is the number of times we sample the binomial distribution.\nIf you type N again, you will see that the numbers increase as you move down the columns of the matrix. Each column represents on sample path of our simulation.\n\n\nShow the code\nhead(N)\n\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]   20   20   20   20   20\n[2,]   26   29   25   27   24\n[3,]   30   34   33   33   26\n[4,]   38   40   39   43   29\n[5,]   43   52   53   51   35\n[6,]   50   58   65   65   39\n\n\nThis is all very nice, but for larger simulations, it just won’t do to look at the matrix of numbers. We need some plots. Here are a few useful ones to start with\n\nplot the first column against the row number plot(N[,1])\nadd some axis labels and a nice title\n\n\n\nShow the code\nplot(N[,1], \n     xlab=\"Time\",ylab=\"Population, N\",\n     main=\"One sample path of the simple birth process\"\n         )\n\n\n\n\n\n\n\n\n\n\nit is also possible to add the title and labels after creating the plot:\n\n\n\nShow the code\nplot(N[,1],ann=FALSE) \ntitle(xlab=\"Time\",\nylab=\"Population, N\", \nmain=\"One sample path of the simple birth process\")\n\n\n\n\n\n\n\n\n\nNotice that we needed to pass `ann=FALSE` to the plot command to suppress the default axis labels\n\nof course you might have noticed that the time axis isn’t really the time, it is the index of the row. What we really want is to start at t=0. What we can do is set up a vector times that contains the times corresponding to each index and pass that to the plot routine. In this case this is just a shift down by 1.\n\n\n\nShow the code\ntimes = 1:T - 1\nplot(times,N[,1],ann=FALSE) \ntitle(xlab=\"Time\", \nylab=\"Population, N\", \nmain=\"One sample path of the simple birth process\")\n\n\n\n\n\n\n\n\n\n\nplot all the columns on a single plot\n\n\n\nShow the code\nmatplot(times,N,ann=FALSE)\ntitle(xlab=\"Time\", \n  ylab=\"Population, N\", \n  main=\"Many sample paths of the simple birth process\")\n\n\n\n\n\n\n\n\n\n\nplot the first, third and fifth columns on a single plot\n\n\n\nShow the code\nmatplot(times,N[,c(1,3,5)],ann=FALSE)\ntitle(xlab=\"Time\", \n  ylab=\"Population, N\", \n  main=\"Many sample paths of the simple birth process\")\n\n\n\n\n\n\n\n\n\nThese values for the initial population and the probability of a birth in unit time are both too high for longer simulations. Change them to something more reasonable, and rerun the code with larger S and T, say 20 and 1000.\nBut wait, we don’t want to be typing everything in again every time we change parameters. That’s just crazy. What we do is wrap the whole thing up as a function and put it in a script. Save the following as a file, call it birthprocess.R, or whatever you like.\n\n\nShow the code\nbirthprocess = function(b = 0.01, No = 2, T = 200, S = 10) {\n    N = matrix(0.0,nrow = T, ncol = S)\n    N[1,] = No\n    for (t in 1:(T-1)) {\n        N[t+1,] = N[t,] + rbinom(S,N[t,],b)\n      }\n    return(N)\n}\n\n\nNotice that we have assigned default values to the arguments of the function. This isn’t necessary, but it can be useful.\nTo source our script from a prompt, enter source(\"birthprocess.R\")\nYou may need to explore your filesystem to learn where you saved the file to. Use the command getwd() to find out what your working directory is.\nTo call our function and assign the results to the matrix N we enter the following at the prompt\n\n\nShow the code\nN = birthprocess(b=0.02,No=2,T=1000,S=20)\n\n\nBy default, a function in R returns the value of the last evaluated expression. This seems to mean the use of the return statement is a matter of preference.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "00-lab-R-intro.html#prettier-plots-with-rs-basic-plot-functions",
    "href": "00-lab-R-intro.html#prettier-plots-with-rs-basic-plot-functions",
    "title": "2  Introduction to R",
    "section": "2.4 prettier plots (with R’s basic plot functions)",
    "text": "2.4 prettier plots (with R’s basic plot functions)\nIf we want to put more than two or three sample paths on a single plot, then we need a way to shrink the point size. There are a few ways to do this. The simplest for our purposes is to set the pch option to something else, like a dot instead of a circle.\n\n\nShow the code\ntimes = 0:(dim(N)[1]-1)\nmatplot(times,N, pch=\".\",ann=FALSE)\ntitle(xlab=\"Time\", \n      ylab=\"Population, N\", \n      main=\"Many sample paths of the simple birth process\")\n\n\n\n\n\n\n\n\n\nTo change to a log scale, use the log option which you can set to either log=\"x\" or log=\"y\":\n\n\nShow the code\nmatplot(times,N[,], pch=\".\", log = \"y\",ann=FALSE)\n\n\n\n\n\n\n\n\n\nIf you don’t have lots and lots of points, the dots might not show up. you can try o or * or some other symbol. Try each of these variations and see if you can deduce the meaning of the options\n\n\nShow the code\nmatplot(times,N, col=1, lty = \"dashed\", type=\"l\",log = \"y\")\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nmatplot(times,N,ann=FALSE, \n        col=c(\"red\",\"green\",\"blue\"), \n  lty = c(\"dashed\",\"dotdash\"), \n  type=\"l\",\n  log = \"y\")\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nmatplot(times,N,ann=FALSE,\n        col=c(\"red\",\"green\",\"blue\"), \n  lty = \"393C3F\",\n  type=\"l\",\n  log = \"y\")\n\n\n\n\n\n\n\n\n\nThere are several ways to add things to plots.\nYou can try the lines or curves functions. For example:\n\n\nShow the code\nlines(times,No*exp(b*times))\n\n\nadds an exponential curve to the plot.\n\n\nShow the code\n    curve(No*exp(b*x),add=TRUE)\n\n\nDoes the same thing.\nYou can make the line thicker.\n\n\nShow the code\n    lines(times,No*exp(b*times),lwd=2)\n\n\nOr you can make it a red, double-dashed line.\n\n\nShow the code\n    lines(times,No*exp(b*times),lwd=2,lty=\"twodash\",col='red')\n\n\nNote that the variants matpoints and matlines will also add points and lines to existing plots. These are probably equivalent to adding add=TRUE to matplot.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "00-lab-R-intro.html#prettier-plots-with-ggplot",
    "href": "00-lab-R-intro.html#prettier-plots-with-ggplot",
    "title": "2  Introduction to R",
    "section": "2.5 Prettier plots with ggplot",
    "text": "2.5 Prettier plots with ggplot\nThe ggplot2 library provides a fancier plotting interface. To use the package, we need to mangle our data into a long format. You could use the tidyr package, but for now, lets play a bit with data frames and rep.\nAssuming we have our data in the matrix N whose columns are separate simulations, we rearrange it into a long format as follows.\n\n\nShow the code\nT = dim(N)[1]\nS = dim(N)[2]\ndf = data.frame(\n       time = rep(1:T, times=S), \n           run = as.factor(rep(1:S,each=T)),\n             population = as.vector(N)\n             )\n\n\nThe times and each arguments to rep indicate the number of times to replicate the vectors 1:T and 1:S. One instance repeats the entire vector S times and the other repeats each element T times. as.factor essentially adds some information to the vector run so that ggplot will treat the entries as factors. We’ll see why when we play with the plots. as.vector simply treats the data in the matrix N as if it were a vector. R stores matrices in column-order, so this effectively stacks the columns into one long vector of length TxS.\nUse str(df) to see the structure of the data frame df\n\n\nShow the code\nstr(df)\n\n\n'data.frame':   20000 obs. of  3 variables:\n $ time      : int  1 2 3 4 5 6 7 8 9 10 ...\n $ run       : Factor w/ 20 levels \"1\",\"2\",\"3\",\"4\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ population: num  2 2 2 2 2 3 3 3 3 3 ...\n\n\nIf this is your fist use of ggplot you may need to install the package. Use Rstudio’s graphical interface, or try install.packages(\"ggplot2\") if you aren’t using a fancy interface.\nFirst we’ll source the package. Then create a simple plot.\n\n\nShow the code\nlibrary(ggplot2)\n\nggplot(df,aes(x=time,y=population)) + \n    geom_line(aes(col=run)) +\n    scale_y_continuous(trans=\"log10\")\n\n\n\n\n\n\n\n\n\nggplot builds the plot up in layers. The ggplot call inputs the data and sets up the aesthetics. I.e., which columns are used. The call to goem_line instructs ggplot to colour the curves according to the factor run. ggplot is powerful, but with power comes complication.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to R</span>"
    ]
  },
  {
    "objectID": "01-lab-BirthProcess.html",
    "href": "01-lab-BirthProcess.html",
    "title": "3  The GillespieSSA routines",
    "section": "",
    "text": "3.1 Initial set up\nOnce you’ve played around a bit, start up a new session and load up the Gillespie routines for the simulations and ggplot2 for some fancy plotting.\nShow the code\nlibrary(GillespieSSA2)\nlibrary(ggplot2)\nYou may need to install the package first. See me if you need help with that.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The GillespieSSA routines</span>"
    ]
  },
  {
    "objectID": "01-lab-BirthProcess.html#the-simple-birth-death-process",
    "href": "01-lab-BirthProcess.html#the-simple-birth-death-process",
    "title": "3  The GillespieSSA routines",
    "section": "3.2 The simple birth death process",
    "text": "3.2 The simple birth death process\nLet’s start with the simple birth death process. This consists of a single state, which we’ll call population, and two transitions, or events: birth and death.\nOur model consists of specifying functions for the rates for the two events.\nFirst, focus on a single individual and suppose this individual gives birth at rate \\(b\\) and dies at rate \\(d\\). For simplicity, suppose the new born individual behaves exactly as the first individual. In particular, she is born a reproductive adult.\nIn a population of \\(N\\) such organisms, operating independently, births would occur at rate \\(bN\\) and deaths at rate \\(dN\\).\nOur model has a single state variable, which we’ll call population, and a two parameters: a birth rate b, and a death rate d. We also need to set a starting value for the population, which we often view as another parameter (the initial state).\nIt is convenient to use named tuples to store defaults for the parameters and initial states.\n\n\nShow the code\ninitial_state &lt;- c(population = 1)\nparams &lt;- c(b = 0.10, d = 0.02)\n\n\nThe SSA algorithm needs the model expressed in terms of reactions and rates, which the GillespieSSA2 package refers to as propensity functions. We have two of these: one for birth and one for death.\n\n\nShow the code\nreactions &lt;- list(\n  # propensity function     effects             name for reaction\n  reaction(\"b * population\", c(population = +1), \"birth\"),\n  reaction(\"d * population\", c(population = -1), \"death\")\n)\n\n\nTo run the simulation, we call ssa with the initial state, reactions, parameters, and a final time. There are several other options you can pass to the routine, but these all have reasonable defaults. There are a few options for expressing the rate, or propensity function. The simplest is likely to enter it as a c++ expression wrapped in quotes.\n\n\nShow the code\nout &lt;- ssa(\n  initial_state = initial_state,\n  reactions = reactions,\n  params = params,\n  method = ssa_exact(),\n  final_time = 100,\n  census_interval = .001,\n  verbose = TRUE\n  )\n\n\nRunning SSA exact with console output every 1 seconds\nwalltime: 0, sim_time: 0\nSSA finished!\n\n\nShow the code\nplot_ssa(out)\n\n\n\n\n\n\n\n\n\nOur simulation run is now stored in out. Entering names(out) or summary(out) at the command prompt shows what the simulation returns. head(out$time) and head(out$state) show the first few events. plot_ssa provides a basic plot of the results.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The GillespieSSA routines</span>"
    ]
  },
  {
    "objectID": "01-lab-BirthProcess.html#density-dependent-rates",
    "href": "01-lab-BirthProcess.html#density-dependent-rates",
    "title": "3  The GillespieSSA routines",
    "section": "3.3 Density dependent rates",
    "text": "3.3 Density dependent rates\nA simple extension of this to include a density dependence is to make the death rate nonlinear. For example, replace the constant per capita death rate \\(d\\) with the linearly increasing rate \\(d + aN\\).\nQuestion: what is the value of \\(N\\) for which the birth rate \\(bN\\) matches the death rate \\(\\left( d + aN \\right) N\\)?\n\n\nShow the code\ninitial_state &lt;- c(population = 1)\nb = 0.1\nd = 0.01\nK = 100\na = (b-d)/K\nparams &lt;- c(b = b, d = d, a = a)\nreactions &lt;- list(\n  # propensity function                     effects             name for reaction\n  reaction(\"b * population\",                c(population = +1), \"birth\"),\n  reaction(\"(d+a*population) * population\", c(population = -1), \"death\")\n)\n\nout &lt;-\n  ssa(\n    initial_state = initial_state,\n    reactions = reactions,\n    params = params,\n    method = ssa_exact(),\n    final_time = 100,\n    census_interval = .001,\n    verbose = TRUE\n  )\n\n\nRunning SSA exact with console output every 1 seconds\nwalltime: 0, sim_time: 0\nSSA finished!\n\n\nShow the code\n# plot_ssa(out)\n\nplot(out$time,out$state,type='s')\n\n\n\n\n\n\n\n\n\nSince we are sampling paths from a stochastic process, we need a wrapper to repeat simulations. See the examples on Predator-Prey models below for more discussion on rbind, data.frame and ggplot.\n\n\nShow the code\nrun_sim = function() {\n  x =ssa(\n    initial_state = initial_state,\n    reactions = reactions,\n    params = params,\n    method = ssa_exact(),\n    final_time = 100,\n    census_interval = .001,\n    verbose = TRUE\n  )\n  return(data.frame(time = x$time, population = x$state))\n}\n\nrepeat_sim = function(n = 5){\n  data = data.frame(time = numeric(0), population = integer(0),run = integer(0))\n  for (i in 1:n){\n    out = run_sim()\n    out$run = i\n    data = rbind(data,out)\n  }\n  return(data)\n}\n \n\nout = repeat_sim(6)\n\n\nRunning SSA exact with console output every 1 seconds\nwalltime: 0, sim_time: 0\nSSA finished!\nRunning SSA exact with console output every 1 seconds\nwalltime: 0, sim_time: 0\nSSA finished!\nRunning SSA exact with console output every 1 seconds\nwalltime: 0, sim_time: 0\nSSA finished!\nRunning SSA exact with console output every 1 seconds\nwalltime: 0, sim_time: 0\nSSA finished!\nRunning SSA exact with console output every 1 seconds\nwalltime: 0, sim_time: 0\nSSA finished!\nRunning SSA exact with console output every 1 seconds\nwalltime: 0, sim_time: 0\nSSA finished!\n\n\nShow the code\nggplot(out,aes(x=time,y=population))+geom_step()+facet_wrap(vars(run),scales='free')",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The GillespieSSA routines</span>"
    ]
  },
  {
    "objectID": "01-lab-BirthProcess.html#adding-an-allee-effect",
    "href": "01-lab-BirthProcess.html#adding-an-allee-effect",
    "title": "3  The GillespieSSA routines",
    "section": "3.4 Adding an Allee Effect",
    "text": "3.4 Adding an Allee Effect\n\n\nShow the code\ninitial_state &lt;- c(population = 10)\nb = 0.1\nd = 0.01\nK = 100\na = (b-d)/K\nc = K/3\n\nparams &lt;- c(b = b, d = d, a = a, c = c)\nreactions &lt;- list(\n  # propensity function                     effects             name for reaction\n  reaction(\"b * population*population/(c+population)\",                c(population = +1), \"birth\"),\n  reaction(\"(d+a*population) * population\", c(population = -1), \"death\")\n  )\n\nout &lt;-\n  ssa(\n    initial_state = initial_state,\n    reactions = reactions,\n    params = params,\n    method = ssa_exact(),\n    final_time = 100,\n    census_interval = .001,\n    verbose = TRUE\n  )\n\n\nRunning SSA exact with console output every 1 seconds\nwalltime: 0, sim_time: 0\nSSA finished!\n\n\nShow the code\n# plot_ssa(out) \n\nplot(out$time,out$state,type='s')",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The GillespieSSA routines</span>"
    ]
  },
  {
    "objectID": "01-lab-BirthProcess.html#the-lotka-voltera-predator-prey-model",
    "href": "01-lab-BirthProcess.html#the-lotka-voltera-predator-prey-model",
    "title": "3  The GillespieSSA routines",
    "section": "3.5 The Lotka-Voltera predator-prey model",
    "text": "3.5 The Lotka-Voltera predator-prey model\nModels can easily be extended to add multiple state variables.\nOne possible implementation of the Lotka-Volterra predator-prey model is to define two state variables, prey and predator, and three reactions, prey birth, predation, and predator death.\n\n\nShow the code\ninitial_state &lt;- c(prey = 1000, predators = 1000)\nparams &lt;- c(c1 = 10, c2 = 0.01, c3 = 10)\nreactions &lt;- list(\n  #        propensity function     effects                       name for reaction\n  reaction(\"c1 * prey\",             c(prey = +1),                 \"prey_birth\"),\n  reaction(\"c2 * prey * predators\", c(prey = -1, predators = +1), \"predation\"),\n  reaction(\"c3 * predators\",        c(predators = -1),            \"predator_death\")\n)\n\nout &lt;-\n  ssa(\n    initial_state = initial_state,\n    reactions = reactions,\n    params = params,\n    method = ssa_exact(),\n    final_time = 5,\n    census_interval = .001,\n    verbose = TRUE\n  )\n\n\nRunning SSA exact with console output every 1 seconds\nwalltime: 0, sim_time: 0\nSSA finished!\n\n\nShow the code\nplot_ssa(out)\n\n\n\n\n\n\n\n\n\nNow we’d really like to sample several solutions from the model to get some idea of the variability. There are many ways to do this. We’ll start by using a fairly simple data frame and a for loop.\n\n\nShow the code\nres_pred_prey = as.data.frame(NULL)\nsamples = 5\nfor (run in 1:samples) {\n    out &lt;-\n        ssa(\n            initial_state = initial_state,\n            reactions = reactions,\n            params = params,\n            method = ssa_exact(),\n            final_time = 5,\n            census_interval = .001,\n            verbose = TRUE\n        )\n    res_pred_prey = rbind(\n      res_pred_prey,\n        data.frame(\n          time = out$time,\n            prey = out$state[,'prey'],\n            predator = out$state[,'predators'],\n            run = as.factor(run)\n        )\n    )\n}\n\n\nRunning SSA exact with console output every 1 seconds\nwalltime: 0, sim_time: 0\nSSA finished!\nRunning SSA exact with console output every 1 seconds\nwalltime: 0, sim_time: 0\nSSA finished!\nRunning SSA exact with console output every 1 seconds\nwalltime: 0, sim_time: 0\nSSA finished!\nRunning SSA exact with console output every 1 seconds\nwalltime: 0, sim_time: 0\nSSA finished!\nRunning SSA exact with console output every 1 seconds\nwalltime: 0, sim_time: 0\nSSA finished!\n\n\nNote the use of data.frame at the end of each loop to wrap each simulation result in a data frame with four columns. Then the use of rbind to append the new data frame to the previous one. The first line sets up an empty data frame (NULL) to start with.\nThe ggplot2 library provides some powerful plotting tools.\n\n\nShow the code\nlibrary(ggplot2)\n\nggplot(res_pred_prey,aes(x=time,y=prey)) +\n  geom_step(aes(col=run))\n\n\n\n\n\n\n\n\n\nShow the code\ndev.new()\nggplot(res_pred_prey,aes(x=time,y=predator)) +\n  geom_step(aes(col=run))\n\n\nNotice ggplot wants the data in a long format. The easiest way to reshape dataframes is with the tidyr package. You can install this on its own or as part of the tidyverse package.\n\n\nShow the code\nlibrary(tidyr)\n\nhead(res_pred_prey)\n\n\n         time prey predator run\n1 0.000000000 1000     1000   1\n2 0.001006049  995      996   1\n3 0.002009907  991      998   1\n4 0.003092260  987     1001   1\n5 0.004053981  983     1003   1\n6 0.005052834  979     1010   1\n\n\nShow the code\nres_long = gather(res_pred_prey,species,population,predator:prey,factor_key=TRUE)\nhead(res_long)\n\n\n         time run  species population\n1 0.000000000   1 predator       1000\n2 0.001006049   1 predator        996\n3 0.002009907   1 predator        998\n4 0.003092260   1 predator       1001\n5 0.004053981   1 predator       1003\n6 0.005052834   1 predator       1010\n\n\nThe second and third inputs of gather are the column names for the long format, and the fourth input is the range of columns from the wide data frame (res_pred_prey) to reshape.\nWe can use ggplot to assign colours and line-types by run and species\n\n\nShow the code\nggplot(res_long,aes(x=time,y=population,linetype=run,col=species)) + geom_step()\n\n\n\n\n\n\n\n\n\nThe result is interesting, but probably too much for one plot. We can put each plot in a panel using facet_grid or facet_plot.\n\n\nShow the code\nggplot(\n    res_long,\n    aes(x=time,y=population,col=species)\n    ) + \ngeom_step() +\nfacet_wrap(~run)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The GillespieSSA routines</span>"
    ]
  },
  {
    "objectID": "02-lab-SDE.html",
    "href": "02-lab-SDE.html",
    "title": "4  The stochastic difference equations and analogous deterministic equations",
    "section": "",
    "text": "4.1 τ-leaping\nAs populations get larger, inter-event times get shorter and simulations using the Gillespie-SSA can be time-consuming. One method to speed up computations, at the expense of some of the exactness of the Gillespie algorithm, is to take fixed time steps of some length \\(\\tau\\) and approximate the number of events as a Poisson random variable.\nConsider again the simple birth process with rate \\(b\\). We found the number of births in a time \\(t\\) was a Poisson random variable with parameter \\(bt\\). These results are easy to extend to the nonlinear birth-death process (see Allen 2011). To simplify our previous notation, suppose \\(b_n\\) and \\(d_n\\) are the birth and death rates given a current population size \\(n\\). Thus in a (vanishingly) small time interval \\(\\tau\\), a single birth occurs with probability \\(b_n\\tau + o(\\tau)\\), a single death occurs with probability \\(d_n\\tau + o(\\tau)\\), a combination of the two events occurs with probability \\(o(\\tau)\\), and neither event occurs with probability \\(1 - (b_n + d_n)\\tau + o(\\tau)\\). Allowing a longer time step, still denoted by \\(\\tau\\), the number of births and deaths occurring during the step are Poisson random variables with rates \\(b_n\\tau\\) and \\(d_n\\tau\\) respectively.\nTo illustrate, use our logistic birth-death process with \\(b_n = bn\\) and \\(d_n = (d+cn)n\\). We’ll refer to \\(b_n\\) and \\(d_n\\) as the birth and rates and to \\(b\\) and \\(d\\) as the per-capita birth and death rates.\nFirst, set up the birth and death rates and pick some parameters.\nShow the code\nbirths = function(n) b*n\ndeaths = function(n) (d+((b-d)/K)*n)*n\nb = 0.01\nd = 0.006\nK=500\nNo = 10\nWith these rates, we should expect on average 5 births and 5 deaths per unit time at a population of 500. If we take a step size of 20 time units, we expect 100 births and 100 deaths on average. This may seem large, but the standard deviation of the Poisson distribution with mean 100 is 10.\nShow the code\nstepsize = 20\ntimes = seq(0,by=stepsize,length=100)\nsamples = 20\nN = matrix(0,nrow=length(times),ncol=samples)\nN[1,] = No\nNow we’ve set up a sequence of times and a matrix to hold the results for 20 sample paths. A simple for loop can be used to fill in the rows of n.\nShow the code\nfor (i in 2:(length(times))) {\n  newbirths = pmax(0,births(N[i-1,])*stepsize)\n  newdeaths = pmax(0,deaths(N[i-1,])*stepsize)\n  N[i,] =  N[i-1,] + rpois(samples,newbirths) - rpois(samples,newdeaths)\n}\n\nmatplot(times,N)\nCreating a heatmap-like image of the results is another good visualization trick, especially for larger samples.\nShow the code\nbreaks = seq(0,1.5*K,length=13)\nbreaks[1] = min(N,na.rm=TRUE)\nbreaks[13] = max(N,na.rm=TRUE)\nH = matrix(0,nrow=length(times),ncol=12)\n\nfor (i in 1:length(times)) { \n    H[i,] = hist(N[i,],breaks=breaks,plot=FALSE)$counts \n}\n\nimage(H)\nDo a few sanity checks before running the for loop. Make sure the breaks do cover the range of N, and that the number of breaks is 12, which is assumed in initializing H.\nTo compare with the results of the Gillespie SSA, compute a few sample paths that way.\nShow the code\nlibrary(GillespieSSA2)\ninitial_state &lt;- c(population = No)\nparams &lt;- c(b = b, d = d, K = K)\nreactions &lt;- list(\n  # propensity function                          effects             name for reaction\n  reaction(\"b * population\",                      c(population = +1), \"birth\"),\n  reaction(\"(d+(b-d)*population/K) * population\", c(population = -1), \"death\")\n)\n\nNssa = matrix(0,nrow=length(times),ncol=samples)\nfor (i in 1:samples) {\nout &lt;-\n  ssa(\n    initial_state = initial_state,\n    reactions = reactions,\n    params = params,\n    method = ssa_exact(),\n    final_time = times[length(times)],\n    census_interval = stepsize,\n        log_buffer=TRUE,\n    verbose = FALSE\n  )\nNssa[1:length(out$state),i] = out$state\n}\n\n\nbreaks[1] = min(Nssa,na.rm=TRUE)\nbreaks[12] = max(Nssa,na.rm=TRUE)\nHssa = matrix(0,nrow=length(times),ncol=12)\nfor (i in 1:length(times)) { Hssa[i,] = hist(Nssa[i,],breaks=breaks,plot=FALSE)$counts }\n\nimage(Hssa)\nτ-leaping can be done with the ssa routines. Details can be found in help pages for ssa_exact, ssa_etl and ssa_btl.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The stochastic difference equations and analogous deterministic equations</span>"
    ]
  },
  {
    "objectID": "02-lab-SDE.html#continuous-state-approximations",
    "href": "02-lab-SDE.html#continuous-state-approximations",
    "title": "4  The stochastic difference equations and analogous deterministic equations",
    "section": "4.2 Continuous state approximations",
    "text": "4.2 Continuous state approximations\nWhen \\(\\lambda\\) is large, the normal distribution with mean \\(\\lambda\\) and variance \\(\\lambda\\) is a reasonable approximation to the Poisson distribution with rate \\(\\lambda\\). Better still, if \\(B\\) and \\(D\\) are normally distributed random variables with means \\(\\mu_b\\) and \\(\\mu_d\\), and variances \\(\\sigma_b^2\\) and \\(\\sigma_d^2\\) respectively, then the difference, \\(B-D\\), has a normal distribution with mean \\(\\mu_b-\\mu_d\\) and variance \\(\\sigma^b+\\sigma^2_d\\).\n\n\nShow the code\nfor (i in 2:(length(times))) {\n  rate_b = births(N[i-1,])*stepsize\n  rate_d = deaths(N[i-1,])*stepsize\n  N[i,] =  N[i-1,] + rate_b-rate_d + sqrt(rate_b+rate_d)*rnorm(samples,0,1)\n}",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The stochastic difference equations and analogous deterministic equations</span>"
    ]
  },
  {
    "objectID": "02-lab-SDE.html#the-analogous-differential-equation",
    "href": "02-lab-SDE.html#the-analogous-differential-equation",
    "title": "4  The stochastic difference equations and analogous deterministic equations",
    "section": "4.3 The analogous differential equation",
    "text": "4.3 The analogous differential equation\nLet \\(N(t)\\) be the random variable denoting the population at time \\(t\\), let \\(dt\\) denote our stepsize, and set \\(dN(t) = N(t+dt) - N(t)\\). This lets us write the stochastic difference equation in the last code snippet as \\[ dN = (B(N)-D(N))dt + dW\\] with \\(dW\\) a normally distributed random variable with mean zero and variance \\((B(N)-D(N))dt\\). Taking a limit as \\(dt\\to0\\) leads us into the realm of stochastic differential equations. Linda Allen (Allen 2011) gives a nice treatment of these in the context of biological applications. Our treatment here will be simpler: we’ll ignore \\(dW\\) and just look at the simpler differential equation.\n\\[\\frac{d}{dt}N = B(N) - D(N)\\]\nIn the case of our logistic birth and death rates, this is\n\\[\\frac{d}{dt}N = rN(1-N/K)\\] with \\(r = b-d\\)\nAs an exercise, solve this separable differential equation via the trick of integrating \\[\\int \\frac{1}{N(1-N/K)}\\, dN = \\int r\\, dt\\] and add the solution to the plot of the stochastic simulation results computed earlier.\n\n\n\n\nAllen, Linda J. S. 2011. An Introduction to Stochastic Processes with Applications to Biology. CRC Press. https://unb.on.worldcat.org/oclc/908670270.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>The stochastic difference equations and analogous deterministic equations</span>"
    ]
  },
  {
    "objectID": "03-predprey.html",
    "href": "03-predprey.html",
    "title": "5  Consumer-Resource Dynamics",
    "section": "",
    "text": "5.1 The Lotka-Volterra Model",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Consumer-Resource Dynamics</span>"
    ]
  },
  {
    "objectID": "03-predprey.html#the-lotka-volterra-model",
    "href": "03-predprey.html#the-lotka-volterra-model",
    "title": "5  Consumer-Resource Dynamics",
    "section": "",
    "text": "5.1.1 Assumptions\nAlfred Lotka (PNAS 1920 6(7):410-415) and Vito Volterra (1926) independently proposed a simple predator-prey model. Lotka was motivated by previous work on rhythmic chemical reactions and oscillations in populations. Volterra was motivated by a question posed by Umberto D’Ancona, a marine biologist who later became Volterra’s son-in-law. D’Ancona was curious if Volterra could use mathematical modelling to explain why the proportion of predatory fish in catches increased when fishing effort decreased during the First World War, and then decreased again when fishing resumed.\nThe classic Lotka-Volterra model is based on a few simple assumptions.\n\nPrey grow exponentially at per capita rate \\(r\\) in absence of the predator.\nPrey are killed at a constant per capita rate \\(a\\) per predator.\nEach prey killed due to predation gives rise to \\(c\\) predators.\nPredator death is at a constant per capita rate \\(m\\).\n\nThe model consists of a pair of differential equations. Here \\(N\\) and \\(P\\) are the prey and predator densities, respectively.\n\\[\\begin{align}\n  \\frac{dN}{dt} &= rN - aNP, \\\\\n  \\frac{dP}{dt} &= c aNP - mP.\n\\end{align}\\]\nThe model has two equilibria:\n\nthe trivial equilibrium \\(X_0 = (0,0)\\),\nand the interior equilibrium \\((\\bar{N},\\bar{P})\\) with\n\\[\\begin{equation*}\n  \\bar{N} = \\frac{m}{c a}, \\qquad\n  \\bar{P} =\\frac{r}{a}.\n\\end{equation*}\\]\n\n\n\n5.1.2 Analysis\n\n5.1.2.1 Rescaling\nRescaling is a simple case of dimensional analysis and can be very helpful in analyzing simple models. The basic idea is that we are free to choose the scale of each variable, and with a clever choice of rescalings we can reduce the number of parameters in the model. Let \\(N^*\\), \\(P^*\\), and \\(t^*\\) be arbitrary constants representing the rescalings, and introduce the rescaled variables as \\(x = N/N^*\\), \\(y = P/P^*\\), and \\(s = t/t^*\\). The equations governing the dynamics of the rescaled variables can be found by a simple application of the chain rule to \\(N^*x(s) = N(t^*s)\\): \\[\\begin{equation*}\n  N^*\\frac{dx}{ds} = \\frac{dN}{dt} \\frac{dt}{ds} = t^* \\frac{dN}{dt}\n\\end{equation*}\\] Similarily, \\(\\frac{dy}{ds} = \\frac{t^*}{P^*}\\frac{dP}{dt}\\). Together, these lead to the equations\n\\[\\begin{align*}\n  \\frac{dx}{ds} &= \\frac{t^*}{N^*} \\left( rN^*x - aN^*xP^*y \\strut \\right),\\\\\n  \\frac{dy}{ds} &= \\frac{t^*}{P^*} \\left( caN^*xP^*y  -  mP^*y \\strut \\right).      \n\\end{align*}\\] The clever trick is to now gather the rescalings and parameters into groups and choose the rescalings to eliminate select groups. \\[\\begin{align*}\n  \\frac{dx}{ds} &= \\framebox{$rt^*$}\\ x - \\framebox{$at^*P^*$}\\ xy ,\\\\\n  \\frac{dy}{ds} &= \\framebox{$cat^*N^*$}\\ xy  -  \\framebox{$mt^*$}\\ y .      \n\\end{align*}\\] This leaves us with four groupings and three rescalings to choose. In general, we would expect to be able to choose the rescalings to set three of the groups to one. Another option is to choose the scalings to set two groups equal to one another. For example, we can choose the rescalings to satisfy the three conditions \\[\\begin{gather*}\n  rt^* = 1, \\\\\n  at^*P^*=1, \\\\\n  cat^*N^*=mt^*.\n\\end{gather*}\\] Solving these leads to the rescalings \\(t^* = 1/r\\), \\(N^* = m/(ca)\\) and \\(P^* = r/a\\). Introducing the new rescaled parameter \\(\\mu = m/r\\), we find\n\\[\\begin{aligned}\n  \\frac{dx}{dt} &= f(x,y) = x(1 - y),           \\\\\n  \\frac{dy}{dt} &= g(x,y) = \\mu y(x -  1),      \n\\end{aligned} \\tag{5.1}\\]\nOur interpretation of the scalings is that time is measured relative to the growth rate of the Prey, Prey densities are measured relative to the ratio of the prey mortality and the prey growth rate per predator, which we previously found to be the equilibrium prey population, and prey densities are measured relative to the ratio of the prey growth rate and the attack rate, which we found to be the equilibrium predator population. The resulting single parameter \\(\\mu\\) is a rescaled predator mortality (\\(\\mu = m/r\\)).\n\n\n5.1.2.2 Phase Plane Analysis\nWe refer to the set of points \\((x,y)\\) with \\(x\\ge0\\) and \\(y\\ge0\\) as our state space. Geometrically, Equations Equation 5.1 specify a vector field on the state space, and solutions of the equations are curves which are tangent to these vectors at each point. A point \\((x,y)\\) for which \\(f(x,y)=g(x,y)=0\\) is an equilibrium solution: these are constant solutions satisfying the differential equations.\nSolutions to \\(f(x,y)=0\\) and \\(g(x,y)=0\\) are referred to as the \\(x\\)-nullclines and \\(y\\)-nullclines respectively. For the Lotka-Volterra model, the \\(x\\)-nullclines are the lines \\(x=0\\) and \\(y=1\\), and the \\(y\\)-nullclines are the lines \\(y=0\\) and \\(x=1\\). The nullclines intersect at the equilibria. The prey population is decreasing on one side of the prey-nullcline, increasing on the other, and the solutions cross the prey-nullcline parallel to the predator-axis. Hence, the nullclines partition the state spatce into regions where populations are increasing or decreasing. Since the nullclines of the Lotka-Volterra model are vertical and horizontal lines, a simple check of the signs of \\(f\\) and \\(g\\) in each of the four regions shows that solutions must oscillate counterclockwise around the nontrivial equilibrium.\n\n\n\n\n\n\nFigure 5.1: Phase Portrait\n\n\n\nAnother trick that often provides insight is to consider the solutions curves as graphs of a function \\(y(x)\\). Since, under reasonable conditions, \\(\\dfrac{dy}{dx} = \\dfrac{dy}{dt}/\\dfrac{dx}{dt}\\), combining the two equations leads to a differential equation for \\(y(x)\\). \\[\\frac{dy}{dx} = \\frac{\\mu y(x -  1)}{x(1 - y)}. \\tag{5.2}\\] This can be integrated as \\[\\Psi(x,y) = \\mu (x - \\log x) + y - \\log y. \\tag{5.3}\\]\nSolutions of Equation 5.2 are level curves of \\(\\Psi\\). Since \\(\\Psi\\) is concave in the positive quadrant, these will be closed curves, or periodic orbits, surrounding the interior equilibrium.\nNow let \\(T\\) be the period of oscillation of a particular solution to the model. From Equation 5.1 we have \\[\\begin{align*}\n  \\frac{1}{T}\\int_{x(t_0)}^{x(t_0+T)} \\frac{1}{x}\\, dx = 1-\\frac{1}{T}\\int_{t_0}^{t_0+T} y(t)\\, dt, \\\\\n  \\text{and}\\quad\n  \\frac{1}{\\mu T}\\int_{y(t_0)}^{y(t_0+T)} \\frac{1}{y}\\, dy = \\frac{1}{T}\\int_{t_0}^{t_0+T} x(t)\\, dt - 1.\n\\end{align*}\\] Since the solutions are periodic with period \\(T\\), the integrals on the left are zero. The integrals on the right are simply the mean values of \\(x\\) and \\(y\\) over one full period. Hence, we conclude that the mean populations on any orbit are equal to the equilibrium populations. Volterra concluded from this that an intervention in a predator-prey system that removes both predator and prey with equal effort, will result in increased average prey populations.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Consumer-Resource Dynamics</span>"
    ]
  },
  {
    "objectID": "03-predprey.html#generalized-lotka-volterra-models",
    "href": "03-predprey.html#generalized-lotka-volterra-models",
    "title": "5  Consumer-Resource Dynamics",
    "section": "5.2 Generalized Lotka-Volterra Models",
    "text": "5.2 Generalized Lotka-Volterra Models\n\n5.2.1 The Volterra Model\nIn 1931, Volterra published an analysis of a predator-prey model with a prey carrying capacity: \\[\\begin{align}\n  \\frac{dN}{dt} &= rN\\left(1-\\frac{N}{K}\\right) - aNP, \\\\\n  \\frac{dP}{dt} &= c aNP - mP.\n\\end{align}\\] The model can be rescaled to yield \\[\\begin{align}\n  x' &= x\\left(1-\\frac{x}{\\kappa}\\right) - xy, \\\\\n  y' &= \\mu y(x - 1).\n\\end{align}\\]\nThese equations represent a similar vector field to the original Lotka-Volterra model. The \\(x\\) nullcline is no longer horizontal, but has the equation \\(y= 1- x/\\kappa\\). The interior equilibrium is at \\(x=1\\), \\(y=1-1/\\kappa\\), which is positive only if \\(\\kappa &gt; 1\\).\n\n\n\n\n\n\nFigure 5.2: Nullclines for the Rosenzweig-MacArthur model\n\n\n\nComputations show the interior equilibrium to be stable, the trivial equilibrium to be a saddle, and the solutions are oscillations decaying to the interior equilibrium.\n\n\n5.2.2 The Rosenzweig-MacArthur Model\nRosenweig and MacArthur (1963) are credited with the addition of a hyperbolic functional response to the classic predator-prey model. \\[\\begin{aligned}\n  \\frac{dN}{dt} &= rN\\left(1-\\frac{N}{K}\\right) - \\frac{aNP}{1 + bN}, \\\\\n  \\frac{dP}{dt} &= c \\frac{aNP}{1 + bN} - mP.\n\\end{aligned} \\tag{5.4}\\]\nThey assume that the rate predators kill prey increases linearly with prey at small densities, but saturates at higher prey densities. The numerical response is taken to be proportional to the functional response, just as in the simpler Lotka-Volterra model.\nThe model has a trivial equilibrium at \\((0,0)\\) and a predator-free equilibrium at \\((0,K)\\). There is a single interior equilibrium \\((\\bar{N},\\bar{P})\\) with \\[\\begin{align*}\n\\bar{N} &= \\frac{m}{ca-mb}, \\\\\n\\bar{P} &= r\\bar{N}(1+b\\bar{N})\\left(1-\\frac{\\bar{N}}{K}\\right).\n\\end{align*}\\] For both \\(\\bar{N}\\) and \\(\\bar{P}\\) to be positive, we must have \\(0 &lt; \\frac{m}{ca-mb} &lt; K\\)\nA stability analysis of the interior fixed point is simplified by writing the system in the Kolmogorov form \\[\\begin{aligned}\n  \\frac{dN}{dt} &= Nf(N), \\\\\n  \\frac{dP}{dt} &= Pg(P),\n\\end{aligned} \\tag{5.5}\\] where \\[f(N,P) = r\\left(1-\\frac{N}{K}\\right) - \\frac{aP}{1 + bN},\\qquad g(N,P) = c \\frac{aN}{1 + bN} - m.\\] The interior equilibrium satisfies \\(f(\\bar{N}) = g(\\bar{P}) = 0\\).\nThe Jacobian at \\((\\bar{N},\\bar{P})\\) is \\[\\begin{equation*}\n\\begin{pmatrix}\n   \\bar{N}\\bar{f}_N & \\bar{N}\\bar{f}_P \\\\\n   \\bar{P}\\bar{g}_N & \\bar{P}\\bar{g}_P\n\\end{pmatrix}\n\\end{equation*}\\] where a bar over a function indicates evaluation at the interior equilibrium. Note that \\(\\bar{g}_P = 0\\), \\(\\bar{f}_P &lt; 0\\) and \\(\\bar{g}_N&gt;0\\), so that the determinant of \\(J\\) is always positive, and the trace of \\(J\\) is \\[\\text{tr}(J) = \\bar{N}\\bar{f}_N = \\frac{rbca}{ca-bm}\\left( \\frac{ca - bm}{ca} - \\frac{1}{Kb}\\right).\\] Hence, according to the Hopf Birfurcation Theorem, the equilibrium changes from a stable to unstable focus as \\(\\bar{f}_N\\) changes from positive to negative. It can further be shown that a stable limit cycle bifurcates from the equilibrium as the trace increases through zero.\nThe equilibrium destabilizes as \\(Kb\\) is increased or as \\(\\frac{bm}{ca}\\) is decreased. The former is often referred to as the paradox of enrichment. The simple Rosenzweig-MacArthur model predicts that an increase in the \\(K\\), the carrying capacity of the prey, can destabilize the equilibrium.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Consumer-Resource Dynamics</span>"
    ]
  },
  {
    "objectID": "03-predprey.html#the-functional-response",
    "href": "03-predprey.html#the-functional-response",
    "title": "5  Consumer-Resource Dynamics",
    "section": "5.3 The Functional Response",
    "text": "5.3 The Functional Response\nTurchin (2003) provides an excellent discussion of the various responses of predators to changes in prey populations. Consider a general predation model of the form\n\\[\\begin{aligned}\n  \\frac{dN}{dt} &= NF(N) - H(N,P)P, \\\\\n  \\frac{dP}{dt} &= G(N,P)P - mP.\n\\end{aligned} \\tag{5.6}\\]\nThe three functions are usually referred to as - the net per capita growth rate \\(F\\), which is assumed independent of predation, - the functional response \\(H\\), which is the rate individual predators kill prey, and - the numerical response \\(G\\), which models the dependence of the per capita predator growth rate on population densities.\nHolling (1959) introduced a simple classification of functional responses of predators into type I, II, or III (see Figure 5.3). Mathematically, type I and II are similar, and represent a saturating response.\n\n\n\n\n\n\nFigure 5.3: Holling’s functional response curves\n\n\n\n\n5.3.1 Phase Planes and Linear Stability Analysis\nConsider the pair of differential equations \\[\\begin{aligned}\n  \\frac{dx}{dt} &= f(x,y), \\\\\n  \\frac{dy}{dt} &= g(x,y),\n\\end{aligned} \\tag{5.7}\\] with initial conditions \\(x(0) = x_0\\), \\(y_0=y_0\\). A system of differential equations that does not depend explicity on the independent variable is said to be autonomous. Since we are usually interested in nonnegative solutions to these equations, the state-space of interest is the set \\((x,y)\\) with \\(x\\ge0\\) and \\(y\\ge 0\\). A solution to the differential equations consists of a pair of functions, \\(x(t)\\) and \\(y(t)\\), which, with reasonable restrictions on \\(f\\) and \\(g\\), will be continuous and differentiable if not for all \\(t\\ge0\\) then at least for some interval \\([0,T)\\). Thus, solutions are either points or curves in the state space, parameterized by the independent variable, \\(t\\). An equilibrium solution of Equation 5.7 is a constant solution \\((x(t),y(t)\\) satisfying \\(f(x(t),y(t)) = g(x(t),y(t)) = 0\\). This can be visualized as a point in state-space.\nGeometrically, Equation 5.7 specifies a vector field on the state space. A solution passing through some point \\((x,y)\\) at time \\(t\\) can be viewed as a curve tangent to the vector \\((f(x,y),g(x,y))\\).\nSolutions to \\(f(x,y)=0\\) and \\(g(x,y)=0\\) are referred to as the \\(x\\)-nullclines and \\(y\\)-nullclines respectively. The equilibrium solutions are found at the intersections of these nullclines. The nullclines partition the state spatce into regions where the \\(x\\) and \\(y\\) components of the solutions are increasing or decreasing.\nIn our analysis of the scaler differential equation, \\(\\dot{x}=f(x)\\), we found that the stability of an equilibrium solution, \\(x^*\\), was determined by the slope \\(f'(x^*)\\). If \\(f'(x^*)&gt;0\\), then \\(x(t)\\) must be decreasing if \\(x(t)&lt;x^*\\) and increasing if \\(x(t)&gt;x^*\\). Thus solutions near \\(x^*\\) move away from \\(x^*\\) if \\(f'(x^*)&gt;0\\), but move towards \\(x^*\\) if \\(f'(x^*)&lt;0\\).\nLet \\(J\\) denote the matrix of partial derivatives of \\(f\\) and \\(g\\) evaluated at the equilibrium: \\[\\begin{equation}\n  J = \\begin{pmatrix} f_x(x^*,y^*) & f_y(x^*,y^*) \\\\ g_x(x^*,y^*) & g_y(x^*,y^*) \\end{pmatrix}\n\\end{equation}\\] Near the equilibrium, we can expand the right hand side of the model as a Taylor series about \\((x^*,y^*)\\): \\[\\begin{equation}\n  \\begin{pmatrix}\n    \\frac{dx}{dt} \\\\  \\frac{dy}{dt}\n  \\end{pmatrix}\n  =\n  \\begin{pmatrix}\n    f(x^*,y^*) \\\\ g(x^*,y^*)\n  \\end{pmatrix}\n  +\n  J\n  \\begin{pmatrix}\n    (x-x^*) \\\\ (y-y^*)\n  \\end{pmatrix}\n  + \\dots\n\\end{equation}\\] Since \\(f\\) and \\(g\\) are zero at an equilibrium, the linearized system is determined by the matrix \\(J\\). There is an important theorem that states that the dynamics of the nonlinear system are topologically equivalent to the dynamics of the linearized system provided all the eigenvalues of \\(J\\) have nonzero real part. The stability of the equilibrium and qualitative nature of the solutions near the equilibrium can be determined from the eigenvalues of \\(J\\) provided none of the eigenvalues of \\(J\\) have zero real part.\nLet \\(u = \\begin{pmatrix}     (x-x^*) \\\\ (y-y^*)   \\end{pmatrix}\\). Then the linearized system is simply \\(\\dot{u} = Ju\\). Now suppose \\(v\\) is an real eigenvector of \\(J\\) associated with the real eigenvalue \\(\\lambda\\). Since, \\(Jv = \\lambda v\\), we can find a solution in the direction of lambda by setting \\(u(t) = a(t)v\\) for a scalar function \\(a\\). \\[\\dot{a}v = Jav = \\lambda av \\Rightarrow \\dot{a} = \\lambda a \\Rightarrow a(t) = a(0)e^{\\lambda t}\\] With a few more theorems on the uniqueness of solutions and linear combinations of solutions that can be found in Logan (2006) we can distill the results down to the diagram of Figure 5.4.\n\n\n\n\n\n\nFigure 5.4: Stability of equilibria based on the trace and determinant of the Jacobian matrix\n\n\n\n\n\n\n\nHolling, Crawford S. 1959. “Some Characteristics of Simple Types of Predation and Parasitism.” The Canadian Entomologist 91 (07): 385–98.\n\n\nLogan, David. 2006. A First Course in Differential Equations. Springer.\n\n\nTurchin, Peter. 2003. Complex Population Dynamics: A Theoretical/Empirical Synthesis. Vol. 35. Princeton University Press. https://unb.on.worldcat.org/oclc/828302490.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Consumer-Resource Dynamics</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Allen, Linda J. S. 2011. An Introduction to Stochastic Processes\nwith Applications to Biology. CRC Press. https://unb.on.worldcat.org/oclc/908670270.\n\n\nHolling, Crawford S. 1959. “Some Characteristics of Simple Types\nof Predation and Parasitism.” The Canadian Entomologist\n91 (07): 385–98.\n\n\nLogan, David. 2006. A First Course in Differential Equations.\nSpringer.\n\n\nTurchin, Peter. 2003. Complex Population Dynamics: A\nTheoretical/Empirical Synthesis. Vol. 35. Princeton University\nPress. https://unb.on.worldcat.org/oclc/828302490.",
    "crumbs": [
      "References"
    ]
  }
]